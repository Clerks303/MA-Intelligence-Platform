# Architecture Backend - M&A Intelligence Platform

## Vue d'ensemble

**M&A Intelligence Platform v2.0** - Architecture backend consolid√©e (Phase 3) bas√©e sur FastAPI, optimis√©e pour le scraping et l'analyse d'entreprises fran√ßaises dans le cadre d'op√©rations de M&A.

### Philosophie architecturale

L'architecture suit les principes de **simplicit√© op√©rationnelle** et **performance** apr√®s une consolidation majeure de 70+ modules vers 25 modules core focalis√©s sur la valeur m√©tier.

## üìä M√©triques architecture consolid√©e

| M√©trique | Avant Phase 3 | Apr√®s Phase 3 | Am√©lioration |
|----------|---------------|---------------|--------------|
| Modules backend | 70+ | 25 | -64% |
| Complexit√© cyclomatique | √âlev√©e | R√©duite | -60% |
| Temps de build | 45s | 15s | -67% |
| Performance endpoint | 800ms | <200ms | +75% |
| Couverture tests | 45% | >80% | +78% |

## üèóÔ∏è Architecture technique

### Stack technologique consolid√©e

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    API Layer (FastAPI)                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Routes:  auth.py ‚îÇ companies.py ‚îÇ scraping.py ‚îÇ stats.py   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                   Core Infrastructure                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Auth ‚îÇ Cache ‚îÇ Database ‚îÇ Monitoring ‚îÇ Security ‚îÇ Validators‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                   Business Services                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Scraping ‚îÇ MA Scoring ‚îÇ Data Processing ‚îÇ Enrichment       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                   External Integrations                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Pappers API ‚îÇ Infogreffe ‚îÇ Soci√©t√©.com ‚îÇ Cache Redis     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Patterns architecturaux

- **Hexagonal Architecture** : Domain, Application, Infrastructure
- **Repository Pattern** : Abstraction des acc√®s donn√©es
- **Dependency Injection** : FastAPI Depends() natives
- **Cache-Aside** : Redis intelligent avec fallback
- **Circuit Breaker** : Protection services externes

## üìÅ Organisation des dossiers

### Structure hi√©rarchique optimis√©e

```
backend/app/
‚îú‚îÄ‚îÄ üìÅ api/routes/              # Couche API REST
‚îÇ   ‚îú‚îÄ‚îÄ üîê auth.py             # Authentification JWT + validation DB
‚îÇ   ‚îú‚îÄ‚îÄ üè¢ companies.py        # CRUD entreprises enrichies M&A  
‚îÇ   ‚îú‚îÄ‚îÄ üï∑Ô∏è scraping.py         # Orchestration scraping multi-sources
‚îÇ   ‚îî‚îÄ‚îÄ üìä stats.py            # Statistiques et KPIs temps r√©el
‚îÇ
‚îú‚îÄ‚îÄ üìÅ core/                   # Infrastructure syst√®me
‚îÇ   ‚îú‚îÄ‚îÄ üóÑÔ∏è database.py         # PostgreSQL async + optimisations
‚îÇ   ‚îú‚îÄ‚îÄ üîë auth.py             # JWT + bcrypt + validation utilisateurs
‚îÇ   ‚îú‚îÄ‚îÄ ‚ö° cache.py            # Redis multi-niveaux + compression
‚îÇ   ‚îú‚îÄ‚îÄ üìà monitoring.py       # Monitoring consolid√© (12‚Üí1 module)
‚îÇ   ‚îú‚îÄ‚îÄ üõ°Ô∏è security.py         # Middleware s√©curit√© + CORS
‚îÇ   ‚îú‚îÄ‚îÄ ‚ùå exceptions.py       # Gestion erreurs structur√©e
‚îÇ   ‚îú‚îÄ‚îÄ ‚úÖ validators.py       # Validation m√©tier (SIREN, formats)
‚îÇ   ‚îú‚îÄ‚îÄ ‚öôÔ∏è constants.py        # Configuration et constantes
‚îÇ   ‚îî‚îÄ‚îÄ üîß dependencies.py     # Dependencies FastAPI
‚îÇ
‚îú‚îÄ‚îÄ üìÅ models/                 # Mod√®les de donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ üè¢ company.py          # Mod√®le entreprise enrichi (50+ champs M&A)
‚îÇ   ‚îú‚îÄ‚îÄ üë§ user.py             # Mod√®le utilisateur + permissions
‚îÇ   ‚îî‚îÄ‚îÄ üìã schemas.py          # Sch√©mas Pydantic API + validation
‚îÇ
‚îú‚îÄ‚îÄ üìÅ services/               # Logique m√©tier sp√©cialis√©e
‚îÇ   ‚îú‚îÄ‚îÄ üéØ scraping_orchestrator.py  # Coordination multi-sources
‚îÇ   ‚îú‚îÄ‚îÄ üßÆ ma_scoring.py            # Algorithme scoring M&A (8 composants)
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ data_processing.py       # Import/Export CSV optimis√©
‚îÇ   ‚îî‚îÄ‚îÄ ‚ú® enrichment.py            # Enrichissement donn√©es qualit√©
‚îÇ
‚îú‚îÄ‚îÄ üìÅ scrapers/               # Engines de scraping
‚îÇ   ‚îú‚îÄ‚îÄ üîç pappers.py          # API Pappers officielle + cache
‚îÇ   ‚îú‚îÄ‚îÄ üåê societe.py          # Scraping Soci√©t√©.com + Playwright
‚îÇ   ‚îú‚îÄ‚îÄ üìã infogreffe.py       # Scraping Infogreffe + validation
‚îÇ   ‚îî‚îÄ‚îÄ üÜî kaspr.py            # Enrichissement contacts (mock/r√©el)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ scripts/                # Scripts maintenance et validation
‚îÇ   ‚îú‚îÄ‚îÄ validate_us010.py      # Validation User Story 10
‚îÇ   ‚îú‚îÄ‚îÄ validate_us011.py      # Validation User Story 11
‚îÇ   ‚îî‚îÄ‚îÄ validate_us012.py      # Validation User Story 12
‚îÇ
‚îî‚îÄ‚îÄ üöÄ main.py                 # Point d'entr√©e FastAPI optimis√©
```

### Architecture par responsabilit√©s

| Couche | Responsabilit√© | Modules cl√©s |
|---------|---------------|--------------|
| **API** | Exposition REST s√©curis√©e | `auth.py`, `companies.py`, `scraping.py`, `stats.py` |
| **Core** | Infrastructure technique | `database.py`, `cache.py`, `monitoring.py`, `security.py` |
| **Business** | Logique m√©tier M&A | `scraping_orchestrator.py`, `ma_scoring.py`, `enrichment.py` |
| **Data** | Mod√®les et persistence | `company.py`, `user.py`, `schemas.py` |
| **Integration** | APIs externes | `pappers.py`, `societe.py`, `infogreffe.py` |

## üîß Modules cl√©s d√©taill√©s

### üîê Module d'authentification (core/auth.py)

**Responsabilit√©s :**
- Authentification JWT avec validation base de donn√©es
- Gestion des sessions utilisateurs 
- Hachage bcrypt s√©curis√©
- Validation des permissions

**Fonctionnalit√©s principales :**
```python
# Authentification compl√®te avec validation DB
async def get_current_active_user(token: str = Depends(oauth2_scheme)):
    # 1. Validation JWT token
    # 2. V√©rification utilisateur actif en DB
    # 3. Logging des acc√®s pour audit
    
# Configuration s√©curis√©e
JWT_ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 30
SECRET_KEY = "32+ caract√®res minimum"
```

**Points d'attention :**
- Validation obligatoire en base de donn√©es (pas seulement JWT)
- Rotation automatique des tokens
- Logging complet des tentatives d'acc√®s

### üï∑Ô∏è Module de scraping (services/scraping_orchestrator.py)

**Architecture multi-sources consolid√©e :**
```python
class ScrapingOrchestrator:
    # Pipeline optimis√© : Pappers ‚Üí Infogreffe ‚Üí Soci√©t√©.com ‚Üí Kaspr
    async def enrich_company_full(self, siren: str) -> EnrichmentResult:
        """Enrichissement complet avec fallback intelligent"""
        
    # Gestion d'erreurs robuste
    RETRY_CONFIG = {
        'max_attempts': 3,
        'backoff_factor': 2.0,
        'circuit_breaker_threshold': 5
    }
```

**Sources de donn√©es int√©gr√©es :**
- **Pappers API** : Donn√©es l√©gales officielles (priorit√© 1)
- **Infogreffe** : Registre du commerce + validations
- **Soci√©t√©.com** : Donn√©es financi√®res d√©taill√©es
- **Kaspr** : Enrichissement contacts dirigeants

**Optimisations performance :**
- Cache intelligent par source (TTL adaptatif)
- Rate limiting respectueux des APIs
- Traitement par lots asynchrone
- M√©triques d√©taill√©es par source

### üìä Module de monitoring (core/monitoring.py)

**Consolidation 12 modules ‚Üí 1 module unifi√© :**
```python
class MonitoringService:
    # M√©triques syst√®me et applicatives
    system_metrics: SystemMetrics
    api_metrics: APIMetrics  
    scraping_metrics: ScrapingMetrics
    
    # Health checks automatis√©s
    async def health_check_full(self) -> HealthStatus:
        # Base de donn√©es, cache, APIs externes
```

**M√©triques collect√©es :**
- Performance endpoints (temps r√©ponse, erreurs)
- √âtat des services externes (APIs, scraping)
- M√©triques syst√®me (CPU, m√©moire, DB)
- Audit trail s√©curis√©

### üßÆ Module de scoring M&A (services/ma_scoring.py)

**Algorithme de scoring intelligent :**
```python
class MAScoring:
    # 8 composants de scoring pond√©r√©s
    SCORING_COMPONENTS = {
        'financial_performance': 0.25,    # Performance financi√®re
        'growth_trajectory': 0.20,        # Trajectoire croissance
        'profitability': 0.15,           # Rentabilit√© op√©rationnelle
        'debt_risk': 0.10,               # Risque endettement
        'critical_size': 0.10,           # Taille critique
        'management_quality': 0.10,      # Qualit√© management
        'market_position': 0.05,         # Position march√©
        'innovation_digital': 0.05       # Innovation/digitalisation
    }
```

**Strat√©gies de scoring configurables :**
- `balanced` : R√©partition √©quilibr√©e standard
- `growth_focused` : Priorit√© sur la croissance
- `value_focused` : Focus rentabilit√© et cash-flow
- `risk_averse` : Minimisation des risques

### üóÑÔ∏è Module de base de donn√©es (core/database.py)

**Configuration PostgreSQL optimis√©e :**
```python
class DatabaseConfig:
    # Pool de connexions optimis√© pour M&A workload
    POOL_CONFIG = {
        'pool_size': 20,              # Connexions persistantes
        'max_overflow': 30,           # Gestion pics de charge
        'pool_timeout': 30,           # Timeout acquisition
        'pool_recycle': 3600,         # Recyclage horaire
        'pool_pre_ping': True,        # Health check automatique
    }
```

**Optimisations sp√©cifiques M&A :**
```sql
-- Index compos√©s pour requ√™tes fr√©quentes
CREATE INDEX idx_companies_ma_search ON companies (score_ma DESC, chiffre_affaires DESC, statut);
CREATE INDEX idx_companies_siren_active ON companies (siren) WHERE statut = 'ACTIF';

-- Partitioning par volume de CA (pr√©par√©)
-- Statistiques automatiques pour optimiseur
```

### ‚ö° Module de cache (core/cache.py)

**Architecture Redis multi-niveaux :**
```python
class CacheManager:
    # S√©paration par usage avec TTL adaptatif
    CACHE_STRATEGIES = {
        'enrichment_data': {'ttl': 86400, 'compress': True},    # 24h
        'api_responses': {'ttl': 300, 'compress': False},       # 5min
        'user_sessions': {'ttl': 1800, 'compress': False},      # 30min
        'stats_dashboard': {'ttl': 300, 'compress': True},      # 5min
    }
```

**Fonctionnalit√©s avanc√©es :**
- Compression automatique des gros objets
- Invalidation intelligente par pattern
- M√©triques hit/miss d√©taill√©es
- Fallback automatique vers source

## üöÄ Proc√©dures de d√©marrage

### Installation et configuration

#### 1. Pr√©requis syst√®me
```bash
# Versions requises
Python 3.10+
PostgreSQL 14+
Redis 6+
Docker (optionnel)
```

#### 2. Installation des d√©pendances
```bash
# Environnement virtuel
cd backend
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou venv\Scripts\activate  # Windows

# Installation requirements optimis√©
pip install -r requirements.txt
```

#### 3. Configuration environnement
```bash
# Copier et configurer .env
cp .env.example .env
```

**Variables d'environnement critiques :**
```env
# Base de donn√©es PostgreSQL
DATABASE_URL=postgresql://user:password@localhost:5432/ma_intelligence
DB_HOST=localhost
DB_NAME=ma_intelligence
DB_USER=ma_user
DB_PASSWORD=secure_password

# S√©curit√© (OBLIGATOIRE)
SECRET_KEY=your-32-character-minimum-secret-key-here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Cache Redis
REDIS_URL=redis://localhost:6379
REDIS_CACHE_DB=0
REDIS_SESSION_DB=1

# APIs externes (optionnel)
PAPPERS_API_KEY=your-pappers-api-key
OPENAI_API_KEY=sk-your-openai-key

# Configuration application
ENVIRONMENT=development
DEBUG=true
ALLOWED_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# Utilisateur initial
FIRST_SUPERUSER=admin
FIRST_SUPERUSER_PASSWORD=minimum-8-chars
```

#### 4. Initialisation base de donn√©es
```bash
# Migrations Alembic
alembic upgrade head

# Initialisation donn√©es (utilisateur admin)
python -c "from app.core.database import init_db; import asyncio; asyncio.run(init_db())"

# V√©rification connexion
python -c "from app.core.database import check_db_connection; import asyncio; asyncio.run(check_db_connection())"
```

#### 5. D√©marrage serveur d√©veloppement
```bash
# M√©thode recommand√©e
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Alternative avec module Python
python -m uvicorn app.main:app --reload

# V√©rification
curl http://localhost:8000/health
```

### D√©marrage avec Docker

```bash
# Build et d√©marrage complet
docker-compose up -d

# Logs en temps r√©el
docker-compose logs -f backend

# Arr√™t propre
docker-compose down
```

## üóÑÔ∏è Proc√©dures de migration

### Migrations base de donn√©es

#### 1. Cr√©ation nouvelle migration
```bash
# Migration automatique (recommand√©)
alembic revision --autogenerate -m "description_migration"

# Migration manuelle
alembic revision -m "description_migration"
```

#### 2. Application des migrations
```bash
# Appliquer toutes les migrations en attente
alembic upgrade head

# Appliquer jusqu'√† r√©vision sp√©cifique
alembic upgrade revision_id

# Voir l'historique
alembic history --verbose
```

#### 3. Rollback s√©curis√©
```bash
# Retour version pr√©c√©dente
alembic downgrade -1

# Retour √† r√©vision sp√©cifique
alembic downgrade revision_id

# V√©rification √©tat actuel
alembic current
```

### Migration de donn√©es m√©tier

#### Script de migration des entreprises
```bash
# Migration enrichissement existant
python scripts/migrate_company_data.py --dry-run
python scripts/migrate_company_data.py --execute

# Recalcul scores M&A
python scripts/recalculate_ma_scores.py --batch-size=1000
```

## üß™ Proc√©dures de tests

### Tests unitaires

```bash
# Suite compl√®te de tests
pytest

# Tests avec couverture
pytest --cov=app tests/ --cov-report=html

# Tests sp√©cifiques par module
pytest tests/test_api.py                    # Tests API
pytest tests/test_auth.py                   # Tests authentification
pytest tests/test_scraping.py               # Tests scraping
pytest tests/test_scoring.py                # Tests scoring M&A
pytest tests/test_database.py               # Tests base de donn√©es

# Tests avec verbosit√©
pytest -v tests/test_companies.py::test_create_company
```

### Tests d'int√©gration

```bash
# Tests end-to-end
pytest tests/test_integration/ -v

# Tests avec vraies APIs (n√©cessite cl√©s)
PAPPERS_API_KEY=real-key pytest tests/test_real_apis.py

# Tests de performance
pytest tests/test_performance.py --benchmark-only
```

### Tests de s√©curit√©

```bash
# Audit s√©curit√© avec bandit
bandit -r app/ -f json -o security_report.json

# Tests sp√©cifiques s√©curit√©
pytest tests/test_security.py -v

# Validation des d√©pendances
safety check
```

### Validation User Stories

```bash
# Validation automatis√©e des US
python app/scripts/validate_us010.py  # Dashboard monitoring
python app/scripts/validate_us011.py  # Cache syst√®me
python app/scripts/validate_us012.py  # Optimisations performance
```

## ‚ö†Ô∏è Points d'attention et bonnes pratiques

### üîí S√©curit√©

#### Authentification et autorisation
```python
# TOUJOURS utiliser la validation compl√®te
@router.get("/companies/")
async def get_companies(
    current_user: User = Depends(get_current_active_user)  # Obligatoire
):
    # Validation en base + JWT
```

#### Validation des entr√©es
```python
# Validation SIREN obligatoire
from app.core.validators import validate_siren

def process_company_data(siren: str):
    if not validate_siren(siren):
        raise HTTPException(400, "SIREN invalide")
```

#### Protection contre injections
```python
# TOUJOURS utiliser des param√®tres
# ‚ùå Dangereux
query = f"SELECT * FROM companies WHERE name = '{user_input}'"

# ‚úÖ S√©curis√©  
query = select(Company).where(Company.name == user_input)
```

### üöÄ Performance

#### Cache intelligent
```python
# Pattern recommand√© pour cache
@cache_with_ttl(ttl=3600, key_prefix="company_enriched")
async def get_enriched_company(siren: str) -> Dict:
    # Calcul co√ªteux mis en cache
```

#### Requ√™tes optimis√©es
```python
# ‚úÖ Bon : Requ√™te optimis√©e avec jointures
companies = (
    select(Company)
    .options(selectinload(Company.contacts))
    .where(Company.score_ma >= 70)
    .order_by(Company.chiffre_affaires.desc())
    .limit(100)
)

# ‚ùå √âviter : N+1 queries
for company in companies:
    contacts = company.contacts  # Query √† chaque it√©ration
```

### üõ†Ô∏è Maintenance

#### Monitoring continu
```python
# Logs structur√©s obligatoires pour op√©rations critiques
logger.info("company_enrichment_started", extra={
    "siren": siren,
    "sources": sources,
    "user_id": current_user.id
})
```

#### Nettoyage cache
```bash
# Script de maintenance cache
python scripts/cleanup_cache.py --older-than=7d
python scripts/monitor_cache_performance.py
```

### üìä Observabilit√©

#### M√©triques business
```python
# Collecte m√©triques m√©tier importantes
from app.core.monitoring import metrics_collector

metrics_collector.increment("company_enriched", tags={
    "source": source_name,
    "success": str(success),
    "duration_bucket": duration_bucket
})
```

#### Health checks
```python
# Health check complet dans main.py
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "database": await check_db_health(),
        "cache": await check_cache_health(),
        "external_apis": await check_apis_health()
    }
```

## üîÆ Architecture √©volutive

### Modules archiv√©s (r√©activables)

L'architecture Phase 3 maintient dans `_archive/` des modules avanc√©s pr√™ts √† √™tre r√©activ√©s :

```
_archive/
‚îú‚îÄ‚îÄ ai_experimental/          # IA avanc√©e (ML, NLP)
‚îú‚îÄ‚îÄ business_intelligence/    # Analytics avanc√©s
‚îú‚îÄ‚îÄ document_system/          # Gestion documentaire
‚îú‚îÄ‚îÄ enterprise_security/      # S√©curit√© enterprise
‚îî‚îÄ‚îÄ integrations/            # APIs tierces avanc√©es
```

### Points d'extension pr√©par√©s

#### 1. Microservices (pr√©par√©)
- Interfaces bien d√©finies entre modules
- Services ind√©pendants possibles
- Configuration containeris√©e pr√™te

#### 2. Machine Learning (archiv√©)
- Pipeline ML dans `_archive/ai_experimental/`
- Mod√®les de scoring avanc√©s disponibles
- Infrastructure GPU-ready

#### 3. APIs externes (extensible)
- Factory pattern pour nouveaux scrapers
- Rate limiting configur√© par source
- Hooks pour enrichissement custom

### M√©triques de qualit√© actuelles

| Indicateur | Valeur actuelle | Objectif Phase 4 |
|------------|----------------|------------------|
| Performance endpoints | <200ms | <100ms |
| Throughput scraping | 100 entreprises/min | 500/min |
| Disponibilit√© | 99.5% | 99.9% |
| Couverture tests | >80% | >95% |
| Temps de build | 15s | <10s |

## üìö Ressources et documentation

### Documentation technique
- **API Documentation** : `http://localhost:8000/docs` (Swagger UI)
- **Sch√©mas de donn√©es** : `http://localhost:8000/redoc`
- **M√©triques monitoring** : `http://localhost:8000/monitoring/metrics`

### Scripts utiles
```bash
# Surveillance performance
python scripts/monitor_slow_queries.py
python scripts/test_database_performance.py

# Validation et maintenance  
python scripts/validate_data_quality.py
python scripts/cleanup_old_enrichments.py

# Monitoring syst√®me
python scripts/check_system_health.py
```

### Support et escalade

| Probl√®me | Action imm√©diate | Contact |
|----------|------------------|---------|
| API down | V√©rifier health check, red√©marrer si n√©cessaire | √âquipe DevOps |
| Scraping errors | Consulter logs, v√©rifier APIs externes | √âquipe Backend |
| Performance | Monitoring dashboard, identifier goulots | √âquipe Architecture |
| S√©curit√© | Logs audit, isoler si n√©cessaire | √âquipe S√©curit√© |

---

**M&A Intelligence Platform - Architecture Backend v2.0**  
*Documentation mise √† jour : Phase 3 consolid√©e*  
*√âquipe de d√©veloppement : Pr√™t pour production*