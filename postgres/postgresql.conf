# PostgreSQL configuration optimisée pour M&A Intelligence Platform
# Performance optimizations for OLTP workload with data analytics

# ==============================================
# CONNEXIONS ET AUTHENTIFICATION
# ==============================================

# Connexions simultanées (ajusté pour Docker + pool SQLAlchemy)
max_connections = 200                     # Total connexions autorisées
superuser_reserved_connections = 3        # Connexions réservées superuser

# Authentification et sécurité
ssl = off                                 # Désactivé en dev (Docker)
password_encryption = scram-sha-256       # Chiffrement moderne des mots de passe

# ==============================================
# MÉMOIRE ET RESSOURCES
# ==============================================

# Mémoire partagée (25% de la RAM disponible - Docker 2GB)
shared_buffers = 512MB                    # Cache pages en mémoire

# Mémoire de travail par connexion
work_mem = 16MB                          # Mémoire pour tris et hash joins
maintenance_work_mem = 128MB             # Mémoire pour VACUUM, CREATE INDEX
max_worker_processes = 8                 # Processus parallèles

# Cache du système d'exploitation (estimation)
effective_cache_size = 1GB              # Estimation cache OS

# ==============================================
# DISK I/O ET WAL
# ==============================================

# WAL (Write-Ahead Logging) optimisé
wal_level = replica                      # Niveau requis pour streaming replication
max_wal_size = 2GB                      # Taille max WAL avant checkpoint
min_wal_size = 512MB                    # Taille min WAL conservée
wal_compression = on                    # Compression WAL
wal_buffers = 16MB                      # Buffers WAL en mémoire

# Checkpoints (écriture périodique sur disque)
checkpoint_completion_target = 0.9      # Étalement des checkpoints
checkpoint_timeout = 10min              # Timeout entre checkpoints

# Cache du système de fichiers
fsync = on                              # IMPORTANT: garantit la durabilité
synchronous_commit = on                 # Attendre confirmation écriture WAL
full_page_writes = on                   # Écriture complète des pages

# ==============================================
# PLANIFICATEUR DE REQUÊTES
# ==============================================

# Coûts estimés pour le planificateur
random_page_cost = 1.1                 # Coût lecture aléatoire (SSD)
effective_io_concurrency = 200         # Concurrent I/O (SSD)
seq_page_cost = 1.0                    # Coût lecture séquentielle

# Statistiques pour le planificateur
default_statistics_target = 200        # Échantillons pour statistiques (plus précis)
constraint_exclusion = partition       # Exclusion contraintes pour partitions

# ==============================================
# PARALLÉLISME
# ==============================================

# Requêtes parallèles (pour analytics)
max_parallel_workers_per_gather = 4    # Workers parallèles par requête
max_parallel_workers = 8               # Total workers parallèles
max_parallel_maintenance_workers = 4   # Workers pour maintenance
parallel_tuple_cost = 0.1              # Coût tuple en parallèle
parallel_setup_cost = 1000             # Coût setup parallélisme

# Seuils de déclenchement du parallélisme
min_parallel_table_scan_size = 8MB     # Taille min pour scan parallèle
min_parallel_index_scan_size = 512kB   # Taille min pour index scan parallèle

# ==============================================
# VACUUM ET AUTOVACUUM
# ==============================================

# Autovacuum agressif pour données fréquemment modifiées
autovacuum = on                         # Activation autovacuum
autovacuum_max_workers = 4              # Workers autovacuum simultanés
autovacuum_naptime = 30s               # Fréquence vérification autovacuum

# Seuils déclenchement autovacuum
autovacuum_vacuum_threshold = 50        # Min rows avant vacuum
autovacuum_analyze_threshold = 50       # Min rows avant analyze
autovacuum_vacuum_scale_factor = 0.1    # Facteur déclenchement vacuum (10%)
autovacuum_analyze_scale_factor = 0.05  # Facteur déclenchement analyze (5%)

# Ressources autovacuum
autovacuum_vacuum_cost_delay = 10ms     # Délai entre opérations
autovacuum_vacuum_cost_limit = 2000     # Limite coût vacuum

# ==============================================
# EXTENSIONS ET MONITORING
# ==============================================

# Extensions chargées au démarrage
shared_preload_libraries = 'pg_stat_statements'

# Configuration pg_stat_statements pour monitoring requêtes
pg_stat_statements.max = 10000          # Nombre max requêtes trackées
pg_stat_statements.track = all          # Tracker toutes les requêtes
pg_stat_statements.track_utility = on   # Tracker CREATE INDEX, VACUUM, etc.
pg_stat_statements.save = on            # Sauvegarder entre redémarrages

# ==============================================
# LOGGING ET DEBUG
# ==============================================

# Logs généraux
log_destination = 'stderr'              # Destination logs
logging_collector = on                  # Collecteur de logs
log_directory = 'pg_log'               # Répertoire logs
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'  # Format nom fichier

# Filtrage des logs
log_min_messages = warning              # Niveau minimum messages
log_min_error_statement = error         # Niveau minimum erreurs
log_min_duration_statement = 1000      # Logguer requêtes > 1s

# Logs de connexion/déconnexion
log_connections = off                   # Logs connexions (verbose en dev)
log_disconnections = off               # Logs déconnexions

# Logs requêtes lentes et utiles
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
log_statement = 'none'                 # Ne pas logger toutes les requêtes
log_lock_waits = on                    # Logger les attentes de verrous

# ==============================================
# OPTIMISATIONS SPÉCIFIQUES APPLICATION
# ==============================================

# Timezone français
timezone = 'Europe/Paris'
datestyle = 'iso, dmy'
lc_messages = 'fr_FR.UTF-8'
lc_monetary = 'fr_FR.UTF-8'
lc_numeric = 'fr_FR.UTF-8'
lc_time = 'fr_FR.UTF-8'

# Optimisations pour JSON (utilisé pour details_complets)
gin_pending_list_limit = 8MB           # Limite pending list pour index GIN

# Optimisations pour text search (recherche entreprises)
default_text_search_config = 'french'  # Configuration français

# ==============================================
# PARAMÈTRES AVANCÉS
# ==============================================

# JIT (Just-In-Time compilation) - désactivé pour requêtes courtes
jit = off                              # JIT désactivé (overhead pour petites requêtes)

# Gestion mémoire
temp_buffers = 32MB                    # Buffers temporaires par session
max_prepared_transactions = 0          # Transactions préparées (non utilisées)

# Timeouts et verrous
lock_timeout = 30s                     # Timeout pour verrous
statement_timeout = 300s               # Timeout requêtes (5 min max)
idle_in_transaction_session_timeout = 600s  # Timeout session idle

# TCP keepalives (pour connexions longues)
tcp_keepalives_idle = 600             # 10 min avant premier keepalive
tcp_keepalives_interval = 30          # Intervalle keepalives
tcp_keepalives_count = 3              # Nombre tentatives

# ==============================================
# CONFIGURATION DÉVELOPPEMENT
# ==============================================

# Paramètres pour développement local (à ajuster en production)
fsync = on                            # TOUJOURS on en production!
synchronous_commit = on               # TOUJOURS on en production!
full_page_writes = on                 # TOUJOURS on en production!

# Logs plus verbeux en développement
log_min_duration_statement = 500     # Logger requêtes > 500ms
log_checkpoints = on                  # Logger les checkpoints
log_autovacuum_min_duration = 1s     # Logger autovacuum > 1s

# ==============================================
# NOTES DE CONFIGURATION
# ==============================================

# Cette configuration est optimisée pour :
# - Workload OLTP (Online Transaction Processing) avec analytics
# - Container Docker avec 2GB RAM
# - SSD storage
# - Données principalement INSERT/UPDATE avec quelques requêtes analytiques
# - Connection pooling via SQLAlchemy

# Pour la production, ajuster :
# - shared_buffers selon la RAM disponible (25% de la RAM totale)
# - max_connections selon la charge
# - work_mem selon la complexité des requêtes
# - Activer SSL et configurer la sécurité réseau